# docker-compose.yml (pour déploiement avec Docker)
version: '3.8'

services:
  flask-app:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama
    volumes:
      - ./app:/app/app
    networks:
      - ollama-network

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - ollama-network
    command: serve

volumes:
  ollama-data:

networks:
  ollama-network:
    driver: bridge

# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# Installation des dépendances système
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copie des fichiers de requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copie du code de l'application
COPY . .

# Exposition du port
EXPOSE 5000

# Variables d'environnement
ENV FLASK_APP=run.py
ENV FLASK_ENV=production

# Commande de démarrage
CMD ["python", "run.py"]

# .dockerignore
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
.env
.venv
pip-log.txt
pip-delete-this-directory.txt
.tox
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.log
.git
.mypy_cache
.pytest_cache
.hypothesis

# Makefile pour automatiser les tâches
.PHONY: install run test clean docker-build docker-run

# Installation des dépendances
install:
	pip install -r requirements.txt

# Démarrage de l'application
run:
	python run.py

# Tests (à implémenter)
test:
	python -m pytest tests/

# Nettoyage
clean:
	find . -type f -name "*.pyc" -delete
	find . -type d -name "__pycache__" -delete

# Construction de l'image Docker
docker-build:
	docker build -t flask-ollama-app .

# Démarrage avec Docker Compose
docker-run:
	docker-compose up -d

# Arrêt des services Docker
docker-stop:
	docker-compose down

# Vérification du statut d'Ollama
check-ollama:
	curl -s http://localhost:11434/api/tags || echo "Ollama non disponible"

# Pull du modèle Mistral
pull-mistral:
	ollama pull mistral:latest

# Script de démarrage (start.sh)
#!/bin/bash

echo "🚀 Démarrage de Flask + Ollama"

# Vérification d'Ollama
if ! command -v ollama &> /dev/null; then
    echo "❌ Ollama n'est pas installé"
    echo "Installez Ollama depuis: https://ollama.ai"
    exit 1
fi

# Démarrage d'Ollama si nécessaire
if ! pgrep -x "ollama" > /dev/null; then
    echo "🔄 Démarrage d'Ollama..."
    ollama serve &
    sleep 5
fi

# Vérification de la disponibilité d'Ollama
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "❌ Ollama n'est pas accessible sur localhost:11434"
    exit 1
fi

# Vérification du modèle Mistral
if ! ollama list | grep -q "mistral:latest"; then
    echo "📥 Téléchargement de Mistral..."
    ollama pull mistral:latest
fi

# Installation des dépendances Python
if [ ! -d "venv" ]; then
    echo "🔧 Création de l'environnement virtuel..."
    python -m venv venv
fi

source venv/bin/activate
pip install -r requirements.txt

# Démarrage de Flask
echo "🌐 Démarrage de Flask sur http://localhost:5000"
python run.py