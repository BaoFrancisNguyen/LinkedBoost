# docker-compose.yml (pour dÃ©ploiement avec Docker)
version: '3.8'

services:
  flask-app:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama
    volumes:
      - ./app:/app/app
    networks:
      - ollama-network

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - ollama-network
    command: serve

volumes:
  ollama-data:

networks:
  ollama-network:
    driver: bridge

# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# Installation des dÃ©pendances systÃ¨me
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copie des fichiers de requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copie du code de l'application
COPY . .

# Exposition du port
EXPOSE 5000

# Variables d'environnement
ENV FLASK_APP=run.py
ENV FLASK_ENV=production

# Commande de dÃ©marrage
CMD ["python", "run.py"]

# .dockerignore
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
.env
.venv
pip-log.txt
pip-delete-this-directory.txt
.tox
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.log
.git
.mypy_cache
.pytest_cache
.hypothesis

# Makefile pour automatiser les tÃ¢ches
.PHONY: install run test clean docker-build docker-run

# Installation des dÃ©pendances
install:
	pip install -r requirements.txt

# DÃ©marrage de l'application
run:
	python run.py

# Tests (Ã  implÃ©menter)
test:
	python -m pytest tests/

# Nettoyage
clean:
	find . -type f -name "*.pyc" -delete
	find . -type d -name "__pycache__" -delete

# Construction de l'image Docker
docker-build:
	docker build -t flask-ollama-app .

# DÃ©marrage avec Docker Compose
docker-run:
	docker-compose up -d

# ArrÃªt des services Docker
docker-stop:
	docker-compose down

# VÃ©rification du statut d'Ollama
check-ollama:
	curl -s http://localhost:11434/api/tags || echo "Ollama non disponible"

# Pull du modÃ¨le Mistral
pull-mistral:
	ollama pull mistral:latest

# Script de dÃ©marrage (start.sh)
#!/bin/bash

echo "ğŸš€ DÃ©marrage de Flask + Ollama"

# VÃ©rification d'Ollama
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama n'est pas installÃ©"
    echo "Installez Ollama depuis: https://ollama.ai"
    exit 1
fi

# DÃ©marrage d'Ollama si nÃ©cessaire
if ! pgrep -x "ollama" > /dev/null; then
    echo "ğŸ”„ DÃ©marrage d'Ollama..."
    ollama serve &
    sleep 5
fi

# VÃ©rification de la disponibilitÃ© d'Ollama
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âŒ Ollama n'est pas accessible sur localhost:11434"
    exit 1
fi

# VÃ©rification du modÃ¨le Mistral
if ! ollama list | grep -q "mistral:latest"; then
    echo "ğŸ“¥ TÃ©lÃ©chargement de Mistral..."
    ollama pull mistral:latest
fi

# Installation des dÃ©pendances Python
if [ ! -d "venv" ]; then
    echo "ğŸ”§ CrÃ©ation de l'environnement virtuel..."
    python -m venv venv
fi

source venv/bin/activate
pip install -r requirements.txt

# DÃ©marrage de Flask
echo "ğŸŒ DÃ©marrage de Flask sur http://localhost:5000"
python run.py